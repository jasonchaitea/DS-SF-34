{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DS-SF-34 | 18 | Natural Language Processing | Codelong | Starter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## >>> One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "import nltk\n",
    "nltk.download()\n",
    "#'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## <<< One-time setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part A | Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk import tokenize, corpus, stem\n",
    "\n",
    "from sklearn import feature_extraction, linear_model, ensemble, model_selection, metrics, decomposition, neighbors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves',\n",
       " u'he',\n",
       " u'him',\n",
       " u'his',\n",
       " u'himself',\n",
       " u'she',\n",
       " u'her',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'it',\n",
       " u'its',\n",
       " u'itself',\n",
       " u'they',\n",
       " u'them',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'themselves',\n",
       " u'what',\n",
       " u'which',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'this',\n",
       " u'that',\n",
       " u'these',\n",
       " u'those',\n",
       " u'am',\n",
       " u'is',\n",
       " u'are',\n",
       " u'was',\n",
       " u'were',\n",
       " u'be',\n",
       " u'been',\n",
       " u'being',\n",
       " u'have',\n",
       " u'has',\n",
       " u'had',\n",
       " u'having',\n",
       " u'do',\n",
       " u'does',\n",
       " u'did',\n",
       " u'doing',\n",
       " u'a',\n",
       " u'an',\n",
       " u'the',\n",
       " u'and',\n",
       " u'but',\n",
       " u'if',\n",
       " u'or',\n",
       " u'because',\n",
       " u'as',\n",
       " u'until',\n",
       " u'while',\n",
       " u'of',\n",
       " u'at',\n",
       " u'by',\n",
       " u'for',\n",
       " u'with',\n",
       " u'about',\n",
       " u'against',\n",
       " u'between',\n",
       " u'into',\n",
       " u'through',\n",
       " u'during',\n",
       " u'before',\n",
       " u'after',\n",
       " u'above',\n",
       " u'below',\n",
       " u'to',\n",
       " u'from',\n",
       " u'up',\n",
       " u'down',\n",
       " u'in',\n",
       " u'out',\n",
       " u'on',\n",
       " u'off',\n",
       " u'over',\n",
       " u'under',\n",
       " u'again',\n",
       " u'further',\n",
       " u'then',\n",
       " u'once',\n",
       " u'here',\n",
       " u'there',\n",
       " u'when',\n",
       " u'where',\n",
       " u'why',\n",
       " u'how',\n",
       " u'all',\n",
       " u'any',\n",
       " u'both',\n",
       " u'each',\n",
       " u'few',\n",
       " u'more',\n",
       " u'most',\n",
       " u'other',\n",
       " u'some',\n",
       " u'such',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'only',\n",
       " u'own',\n",
       " u'same',\n",
       " u'so',\n",
       " u'than',\n",
       " u'too',\n",
       " u'very',\n",
       " u's',\n",
       " u't',\n",
       " u'can',\n",
       " u'will',\n",
       " u'just',\n",
       " u'don',\n",
       " u'should',\n",
       " u'now',\n",
       " u'd',\n",
       " u'll',\n",
       " u'm',\n",
       " u'o',\n",
       " u're',\n",
       " u've',\n",
       " u'y',\n",
       " u'ain',\n",
       " u'aren',\n",
       " u'couldn',\n",
       " u'didn',\n",
       " u'doesn',\n",
       " u'hadn',\n",
       " u'hasn',\n",
       " u'haven',\n",
       " u'isn',\n",
       " u'ma',\n",
       " u'mightn',\n",
       " u'mustn',\n",
       " u'needn',\n",
       " u'shan',\n",
       " u'shouldn',\n",
       " u'wasn',\n",
       " u'weren',\n",
       " u'won',\n",
       " u'wouldn']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(document):\n",
    "    document = document.encode('utf-8')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenize.word_tokenize(document)\n",
    "\n",
    "    # Remove punctuation in tokens and then remove empty tokens\n",
    "    tokens = [token.translate(None, string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if not token in corpus.stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'wait', 'another', 'third']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(\"This is a sentence...  Wait, here's another.  And a third!\")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [Stemmer.stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentenc', 'wait', u'anoth', 'third']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Stemmer.stem_tokens(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part B | Book reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Below, we will be analyzing a partial list of the reviews for J.K. Rowling's The Casual Vacancy.  (https://www.amazon.com/dp/0316228532)  We scrapped this dataset during class 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'dataset-18-reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>R3TUANQ2EB3ECB</td>\n",
       "      <td>MichaelMichaels</td>\n",
       "      <td>Skip it. Life is too short.</td>\n",
       "      <td>I've never read any of the Harry Potter books ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>R2DD03ZZ4218VW</td>\n",
       "      <td>Frans van Wyk</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Excellent Read with a lot of real life values ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>R296NVKLH5QS4W</td>\n",
       "      <td>Sabina Duke</td>\n",
       "      <td>Characters</td>\n",
       "      <td>Hard to keep the characters straight</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>R3MP7W8LH6VHU8</td>\n",
       "      <td>Jen Blau</td>\n",
       "      <td>GIVE IT A CHANCE!</td>\n",
       "      <td>I almost put this book down. I'm new to Rowlin...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>RZWP48RKJCXT1</td>\n",
       "      <td>Lilith Eleanor</td>\n",
       "      <td>Frighteningly good</td>\n",
       "      <td>Amazing. Rowling combines fantastic writing wi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>RT2TE0W92SL67</td>\n",
       "      <td>Tricia K.</td>\n",
       "      <td>Seriously?  $17 bucks for a computer file???  ...</td>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R14ZGYPSP9H0Y7</td>\n",
       "      <td>Pretzel</td>\n",
       "      <td>A must read</td>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R1913ISIDAGQ1A</td>\n",
       "      <td>Prodigy</td>\n",
       "      <td>I love it</td>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R2JY771IW7RI3R</td>\n",
       "      <td>David Katz</td>\n",
       "      <td>Kendle price too expensive</td>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R22B7K1DUJR6ZN</td>\n",
       "      <td>M. A. Barnett</td>\n",
       "      <td>too expensive</td>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5861 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date              id           author  \\\n",
       "0     2017-04-21  R3TUANQ2EB3ECB  MichaelMichaels   \n",
       "1     2017-04-20  R2DD03ZZ4218VW    Frans van Wyk   \n",
       "2     2017-04-20  R296NVKLH5QS4W      Sabina Duke   \n",
       "3     2017-04-05  R3MP7W8LH6VHU8         Jen Blau   \n",
       "4     2017-04-04   RZWP48RKJCXT1   Lilith Eleanor   \n",
       "...          ...             ...              ...   \n",
       "5856  2012-09-27   RT2TE0W92SL67        Tricia K.   \n",
       "5857  2012-09-27  R14ZGYPSP9H0Y7          Pretzel   \n",
       "5858  2012-09-27  R1913ISIDAGQ1A          Prodigy   \n",
       "5859  2012-09-27  R2JY771IW7RI3R       David Katz   \n",
       "5860  2012-09-27  R22B7K1DUJR6ZN    M. A. Barnett   \n",
       "\n",
       "                                                  title  \\\n",
       "0                           Skip it. Life is too short.   \n",
       "1                                            Four Stars   \n",
       "2                                            Characters   \n",
       "3                                     GIVE IT A CHANCE!   \n",
       "4                                    Frighteningly good   \n",
       "...                                                 ...   \n",
       "5856  Seriously?  $17 bucks for a computer file???  ...   \n",
       "5857                                        A must read   \n",
       "5858                                          I love it   \n",
       "5859                         Kendle price too expensive   \n",
       "5860                                      too expensive   \n",
       "\n",
       "                                                   body  star_rating  \n",
       "0     I've never read any of the Harry Potter books ...          1.0  \n",
       "1     Excellent Read with a lot of real life values ...          4.0  \n",
       "2                  Hard to keep the characters straight          4.0  \n",
       "3     I almost put this book down. I'm new to Rowlin...          5.0  \n",
       "4     Amazing. Rowling combines fantastic writing wi...          5.0  \n",
       "...                                                 ...          ...  \n",
       "5856  Premise sounds dull as dirt.  For $17 for a co...          1.0  \n",
       "5857  The depth of character development and storyli...          5.0  \n",
       "5858  The book was great and I will love to re-read ...          5.0  \n",
       "5859  I started to order the kindle edition and than...          5.0  \n",
       "5860  I would love to buy this book but it is too ex...          1.0  \n",
       "\n",
       "[5861 rows x 6 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.drop(['date', 'id', 'author', 'title'],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've never read any of the Harry Potter books ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent Read with a lot of real life values ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard to keep the characters straight</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I almost put this book down. I'm new to Rowlin...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing. Rowling combines fantastic writing wi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5861 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  star_rating\n",
       "0     I've never read any of the Harry Potter books ...          1.0\n",
       "1     Excellent Read with a lot of real life values ...          4.0\n",
       "2                  Hard to keep the characters straight          4.0\n",
       "3     I almost put this book down. I'm new to Rowlin...          5.0\n",
       "4     Amazing. Rowling combines fantastic writing wi...          5.0\n",
       "...                                                 ...          ...\n",
       "5856  Premise sounds dull as dirt.  For $17 for a co...          1.0\n",
       "5857  The depth of character development and storyli...          5.0\n",
       "5858  The book was great and I will love to re-read ...          5.0\n",
       "5859  I started to order the kindle edition and than...          5.0\n",
       "5860  I would love to buy this book but it is too ex...          1.0\n",
       "\n",
       "[5861 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body           3\n",
       "star_rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Positive, neutral, and negatives reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "df['polarity'] = df.star_rating.map({1: -1, 2: -1, 3: 0, 4: 1, 5: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>2177</td>\n",
       "      <td>2177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2711</td>\n",
       "      <td>2711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          body  star_rating\n",
       "polarity                   \n",
       "-1        2177         2177\n",
       " 0         970          970\n",
       " 1        2711         2711"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('polarity').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2711\n",
       "-1    2177\n",
       " 0     970\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ns = df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2711\n",
       "-1    2177\n",
       " 0     970\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for polarity in [-1, 0, 1]:\n",
    "    n = ns[polarity] - ns.min()\n",
    "    index = df[df.polarity == polarity].sample(n = n, random_state = 0).index\n",
    "    df.drop(index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    970\n",
       "-1    970\n",
       " 0    970\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature matrix and response vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "X = df.body\n",
    "\n",
    "c = df.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_c, test_c = model_selection.train_test_split(X, c, stratify = c, train_size = .6, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    582\n",
       " 1    582\n",
       "-1    582\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    388\n",
       " 1    388\n",
       " 0    388\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TF-IDF and `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomTokenizer(object):\n",
    "    def __call__(self, document):\n",
    "        tokens = tokenize_text(document)\n",
    "        tokens = Stemmer.stem_tokens(tokens)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(tokenizer = CustomTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<__main__.CustomTokenizer object at 0x10a75f190>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = vectorizer.transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['012315',\n",
       " '08',\n",
       " '1',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1012',\n",
       " '105',\n",
       " '11',\n",
       " '110',\n",
       " '12',\n",
       " '120',\n",
       " '13',\n",
       " '130',\n",
       " '132',\n",
       " '14',\n",
       " '142',\n",
       " '143',\n",
       " '149',\n",
       " '1495',\n",
       " '1499',\n",
       " '15',\n",
       " '150',\n",
       " '17',\n",
       " '170',\n",
       " '175',\n",
       " '1799',\n",
       " '18',\n",
       " '1860',\n",
       " '18th',\n",
       " '1950',\n",
       " u'1960',\n",
       " '1984',\n",
       " '19th',\n",
       " '1star',\n",
       " '2',\n",
       " '20',\n",
       " '200',\n",
       " '2012',\n",
       " '2015',\n",
       " '2016',\n",
       " '21',\n",
       " '21st',\n",
       " '23',\n",
       " '230am',\n",
       " '236',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '27',\n",
       " '28',\n",
       " '2nd',\n",
       " '3',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '31',\n",
       " '32',\n",
       " '34',\n",
       " '35',\n",
       " '355',\n",
       " '380',\n",
       " '3d',\n",
       " '3rd',\n",
       " '4',\n",
       " '40',\n",
       " '400',\n",
       " '40ish',\n",
       " '412star',\n",
       " '44',\n",
       " '45',\n",
       " '450',\n",
       " '5',\n",
       " '50',\n",
       " '500',\n",
       " '500th',\n",
       " '503',\n",
       " '505',\n",
       " '50th',\n",
       " '56',\n",
       " '57',\n",
       " '6',\n",
       " '60',\n",
       " '600',\n",
       " '6080',\n",
       " '62',\n",
       " '6th',\n",
       " '7',\n",
       " '70',\n",
       " '72',\n",
       " '75',\n",
       " '77',\n",
       " '8',\n",
       " '80',\n",
       " '800',\n",
       " '89',\n",
       " '90',\n",
       " '92',\n",
       " '93',\n",
       " '98',\n",
       " '9997',\n",
       " 'aand',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " u'abil',\n",
       " 'abject',\n",
       " u'abl',\n",
       " u'abnorm',\n",
       " u'abort',\n",
       " 'abound',\n",
       " u'aboutth',\n",
       " 'abraham',\n",
       " 'abrupt',\n",
       " u'abruptli',\n",
       " u'absenc',\n",
       " u'absentmindedli',\n",
       " u'absolut',\n",
       " u'absorb',\n",
       " u'absurd',\n",
       " u'abund',\n",
       " u'abus',\n",
       " u'abut',\n",
       " u'accent',\n",
       " u'accept',\n",
       " u'access',\n",
       " u'accid',\n",
       " u'accident',\n",
       " u'accomplish',\n",
       " u'accord',\n",
       " 'account',\n",
       " u'accur',\n",
       " u'accuraci',\n",
       " u'accus',\n",
       " u'accustom',\n",
       " u'acerb',\n",
       " u'ach',\n",
       " u'achiev',\n",
       " u'acknowledg',\n",
       " u'acom',\n",
       " 'acorn',\n",
       " u'acquaint',\n",
       " u'across',\n",
       " u'act',\n",
       " u'action',\n",
       " u'actionpack',\n",
       " u'activ',\n",
       " u'activit',\n",
       " 'actor',\n",
       " u'actress',\n",
       " u'actual',\n",
       " 'acumen',\n",
       " u'acut',\n",
       " u'ad',\n",
       " u'adapt',\n",
       " 'add',\n",
       " u'addict',\n",
       " u'addit',\n",
       " u'address',\n",
       " 'adept',\n",
       " u'adeptli',\n",
       " u'adequ',\n",
       " u'adjac',\n",
       " u'adject',\n",
       " 'adjust',\n",
       " u'adloesc',\n",
       " u'administ',\n",
       " u'admir',\n",
       " 'admit',\n",
       " u'admittedli',\n",
       " u'adolesc',\n",
       " u'ador',\n",
       " 'adrian',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " u'adultthem',\n",
       " u'adut',\n",
       " u'advantag',\n",
       " u'adventur',\n",
       " u'advert',\n",
       " u'advertis',\n",
       " u'advic',\n",
       " u'advis',\n",
       " u'advoc',\n",
       " 'affair',\n",
       " u'affect',\n",
       " 'affluent',\n",
       " 'afraid',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " u'afterward',\n",
       " 'agatha',\n",
       " 'age',\n",
       " u'ageless',\n",
       " u'agenda',\n",
       " 'agent',\n",
       " 'agesa',\n",
       " u'aggress',\n",
       " u'agit',\n",
       " 'ago',\n",
       " u'agre',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " u'aim',\n",
       " u'aimless',\n",
       " u'air',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'al',\n",
       " u'ala',\n",
       " 'albeit',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " u'alexand',\n",
       " u'alik',\n",
       " u'aliv',\n",
       " u'alleg',\n",
       " u'allegi',\n",
       " u'allegor',\n",
       " 'alley',\n",
       " u'alli',\n",
       " 'allnight',\n",
       " 'allot',\n",
       " u'allow',\n",
       " 'allround',\n",
       " u'alltim',\n",
       " u'allus',\n",
       " u'allveri',\n",
       " 'almost',\n",
       " u'alon',\n",
       " 'along',\n",
       " 'alot',\n",
       " u'alreadi',\n",
       " 'alright',\n",
       " 'also',\n",
       " u'altern',\n",
       " 'although',\n",
       " u'altogeth',\n",
       " 'altruism',\n",
       " u'alway',\n",
       " 'amateurish',\n",
       " u'amaz',\n",
       " u'amazingli',\n",
       " 'amazom',\n",
       " 'amazon',\n",
       " 'amazoncom',\n",
       " 'amazonon',\n",
       " u'ambigu',\n",
       " u'ambit',\n",
       " u'ambiti',\n",
       " u'ambival',\n",
       " 'america',\n",
       " 'american',\n",
       " u'ami',\n",
       " 'amidst',\n",
       " u'amiss',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " u'amus',\n",
       " u'analog',\n",
       " u'andi',\n",
       " 'andor',\n",
       " u'anecdot',\n",
       " 'aneurysm',\n",
       " u'angel',\n",
       " 'anger',\n",
       " u'angl',\n",
       " u'anglophil',\n",
       " u'angri',\n",
       " 'angst',\n",
       " 'ann',\n",
       " u'anniversari',\n",
       " u'announc',\n",
       " u'annoy',\n",
       " u'anoth',\n",
       " u'anotherth',\n",
       " u'answer',\n",
       " u'antagonist',\n",
       " u'anticip',\n",
       " u'anticlimact',\n",
       " u'anticlimat',\n",
       " u'antifield',\n",
       " u'antihero',\n",
       " u'antiheroin',\n",
       " u'antip',\n",
       " u'antithesi',\n",
       " u'anxieti',\n",
       " u'anxiou',\n",
       " u'anybodi',\n",
       " 'anyday',\n",
       " u'anymor',\n",
       " u'anyon',\n",
       " u'anyth',\n",
       " 'anytown',\n",
       " 'anyway',\n",
       " u'anywher',\n",
       " 'apart',\n",
       " u'apathi',\n",
       " u'apologet',\n",
       " u'appal',\n",
       " u'appar',\n",
       " 'appeal',\n",
       " u'appear',\n",
       " 'applaud',\n",
       " u'applaus',\n",
       " u'appli',\n",
       " u'appreci',\n",
       " u'apprehens',\n",
       " u'apprentic',\n",
       " 'approach',\n",
       " u'appropri',\n",
       " u'approv',\n",
       " u'approxim',\n",
       " 'apt',\n",
       " u'arc',\n",
       " u'archetyp',\n",
       " 'archvillain',\n",
       " u'area',\n",
       " 'arena',\n",
       " 'arf',\n",
       " u'arguabl',\n",
       " u'argument',\n",
       " u'aris',\n",
       " u'arm',\n",
       " u'armi',\n",
       " u'aros',\n",
       " 'around',\n",
       " u'arous',\n",
       " u'arrang',\n",
       " 'array',\n",
       " u'arriv',\n",
       " u'arrog',\n",
       " 'art',\n",
       " u'artist',\n",
       " u'artistri',\n",
       " 'asan',\n",
       " 'asap',\n",
       " u'asham',\n",
       " u'asid',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " u'aspir',\n",
       " 'assault',\n",
       " u'assess',\n",
       " u'assid',\n",
       " u'assign',\n",
       " u'associ',\n",
       " u'assuag',\n",
       " u'assum',\n",
       " u'assumpt',\n",
       " u'assur',\n",
       " u'astonish',\n",
       " u'astonishingli',\n",
       " u'astound',\n",
       " u'astoundingli',\n",
       " u'astut',\n",
       " 'ate',\n",
       " u'athlet',\n",
       " u'atmospher',\n",
       " 'atrisk',\n",
       " u'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " u'attend',\n",
       " u'attent',\n",
       " u'attitud',\n",
       " 'attorney',\n",
       " u'attract',\n",
       " u'audibl',\n",
       " u'audienc',\n",
       " 'audio',\n",
       " 'audiobook',\n",
       " 'aunt',\n",
       " 'austen',\n",
       " 'australia',\n",
       " u'authent',\n",
       " 'author',\n",
       " u'authoress',\n",
       " u'authori',\n",
       " u'avail',\n",
       " u'avalanch',\n",
       " u'averag',\n",
       " 'avid',\n",
       " u'avoid',\n",
       " u'aw',\n",
       " u'await',\n",
       " u'awak',\n",
       " u'awar',\n",
       " 'away',\n",
       " u'awe',\n",
       " u'awesom',\n",
       " u'awhil',\n",
       " 'awkward',\n",
       " u'awkwardli',\n",
       " u'babi',\n",
       " 'back',\n",
       " u'backbit',\n",
       " 'backdoor',\n",
       " 'backdrop',\n",
       " u'backfir',\n",
       " u'background',\n",
       " u'backstab',\n",
       " u'backstori',\n",
       " u'backward',\n",
       " 'bad',\n",
       " u'badli',\n",
       " 'bag',\n",
       " u'balanc',\n",
       " u'ball',\n",
       " u'banal',\n",
       " 'band',\n",
       " 'barbara',\n",
       " 'bare',\n",
       " u'barri',\n",
       " u'barrymor',\n",
       " u'base',\n",
       " u'basebal',\n",
       " u'bash',\n",
       " u'basi',\n",
       " u'basic',\n",
       " 'basket',\n",
       " u'basketbal',\n",
       " 'bat',\n",
       " u'bate',\n",
       " 'bath',\n",
       " u'bathroom',\n",
       " 'bbc',\n",
       " 'bc',\n",
       " u'be',\n",
       " 'beach',\n",
       " 'bear',\n",
       " u'beast',\n",
       " u'beat',\n",
       " u'beater',\n",
       " u'beauti',\n",
       " u'becacaus',\n",
       " u'becam',\n",
       " u'becom',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " u'bedtim',\n",
       " 'began',\n",
       " 'beget',\n",
       " u'begin',\n",
       " u'beguil',\n",
       " u'behav',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " u'being',\n",
       " 'belief',\n",
       " u'believ',\n",
       " 'bellchapel',\n",
       " u'belli',\n",
       " u'belliger',\n",
       " u'belong',\n",
       " u'belov',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'beset',\n",
       " 'best',\n",
       " u'bestsel',\n",
       " u'besttak',\n",
       " u'betray',\n",
       " 'better',\n",
       " u'bevi',\n",
       " 'beyond',\n",
       " u'beyondthi',\n",
       " u'bias',\n",
       " u'bibl',\n",
       " u'bibliophil',\n",
       " u'bicker',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " u'bigotri',\n",
       " 'billion',\n",
       " u'billionair',\n",
       " u'binchi',\n",
       " u'bind',\n",
       " 'bing',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " u'bite',\n",
       " 'bitter',\n",
       " u'bitterlki',\n",
       " 'black',\n",
       " u'blackandwhit',\n",
       " u'blade',\n",
       " 'blame',\n",
       " 'blanch',\n",
       " 'bland',\n",
       " 'blank',\n",
       " u'blatantli',\n",
       " 'bleak',\n",
       " 'bleaker',\n",
       " u'bleed',\n",
       " 'blend',\n",
       " u'bless',\n",
       " 'blind',\n",
       " u'blister',\n",
       " u'bloat',\n",
       " u'blockbust',\n",
       " 'blog',\n",
       " 'bloodbath',\n",
       " u'bloodi',\n",
       " u'bloodthirsti',\n",
       " 'blossom',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blunt',\n",
       " u'blur',\n",
       " 'blurb',\n",
       " u'boar',\n",
       " 'board',\n",
       " u'bog',\n",
       " u'bogg',\n",
       " u'bold',\n",
       " u'boldli',\n",
       " u'bomb',\n",
       " u'bone',\n",
       " 'boo',\n",
       " u'book',\n",
       " 'booker',\n",
       " 'booki',\n",
       " 'bookjust',\n",
       " u'bookmark',\n",
       " 'booknot',\n",
       " u'booksbett',\n",
       " 'bookslet',\n",
       " 'bookso',\n",
       " u'bookstor',\n",
       " u'bookth',\n",
       " u'boom',\n",
       " 'boorish',\n",
       " u'border',\n",
       " u'bore',\n",
       " 'boredom',\n",
       " 'boreingfound',\n",
       " 'borrow',\n",
       " u'bother',\n",
       " 'bottom',\n",
       " u'bottomlin',\n",
       " 'bought',\n",
       " u'bounc',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'brace',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brandnew',\n",
       " 'brava',\n",
       " 'bravado',\n",
       " 'brave',\n",
       " 'bravo',\n",
       " 'breadth',\n",
       " u'break',\n",
       " 'breakaway',\n",
       " 'breaker',\n",
       " u'breast',\n",
       " u'breath',\n",
       " u'breathtak',\n",
       " 'breed',\n",
       " u'bridgewat',\n",
       " 'brief',\n",
       " u'briefli',\n",
       " 'brighter',\n",
       " 'brightest',\n",
       " 'brillant',\n",
       " u'brillianc',\n",
       " 'brilliant',\n",
       " 'brillianti',\n",
       " u'brilliantli',\n",
       " 'bring',\n",
       " u'brit',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'britisk',\n",
       " 'britney',\n",
       " 'broad',\n",
       " 'broken',\n",
       " u'brooksid',\n",
       " u'broomstick',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brutal',\n",
       " u'bu',\n",
       " u'buck',\n",
       " u'bucket',\n",
       " u'bucol',\n",
       " 'budget',\n",
       " 'buffet',\n",
       " u'buffoon',\n",
       " u'build',\n",
       " 'built',\n",
       " 'builtin',\n",
       " u'bull',\n",
       " u'bulli',\n",
       " u'bum',\n",
       " 'bummer',\n",
       " 'bunch',\n",
       " 'burner',\n",
       " 'burst',\n",
       " u'busi',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'c',\n",
       " 'ca',\n",
       " u'calam',\n",
       " 'calendar',\n",
       " u'calib',\n",
       " u'call',\n",
       " 'came',\n",
       " 'camp',\n",
       " u'campaign',\n",
       " u'canari',\n",
       " u'candid',\n",
       " u'candl',\n",
       " 'canon',\n",
       " 'cant',\n",
       " 'cantwo',\n",
       " u'capabl',\n",
       " u'capac',\n",
       " u'capit',\n",
       " 'capitalist',\n",
       " u'capitil',\n",
       " u'captiv',\n",
       " u'captur',\n",
       " 'car',\n",
       " u'caract',\n",
       " 'cardboard',\n",
       " u'cardboardlik',\n",
       " 'care',\n",
       " 'career',\n",
       " u'caricatur',\n",
       " 'carol',\n",
       " u'carpentri',\n",
       " u'carri',\n",
       " 'cartoonish',\n",
       " 'case',\n",
       " u'cash',\n",
       " 'cast',\n",
       " u'castl',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'cataclysm',\n",
       " 'catalyst',\n",
       " u'catapult',\n",
       " u'catastroph',\n",
       " 'catch',\n",
       " 'catcher',\n",
       " u'categor',\n",
       " u'categori',\n",
       " 'caught',\n",
       " 'cauldron',\n",
       " u'caus',\n",
       " 'causal',\n",
       " 'caustic',\n",
       " 'cave',\n",
       " 'caveat',\n",
       " 'cd',\n",
       " u'celebr',\n",
       " 'cent',\n",
       " u'center',\n",
       " u'centr',\n",
       " 'central',\n",
       " u'centuri',\n",
       " 'certain',\n",
       " u'certainli',\n",
       " 'cesspool',\n",
       " 'chadha',\n",
       " 'chain',\n",
       " 'chairman',\n",
       " u'chalk',\n",
       " u'challeng',\n",
       " u'challengesstruggl',\n",
       " u'chanc',\n",
       " u'chang',\n",
       " u'chao',\n",
       " u'chapter',\n",
       " u'charact',\n",
       " u'character',\n",
       " 'characterdriven',\n",
       " u'characteris',\n",
       " u'characterist',\n",
       " 'charactersand',\n",
       " 'charactersplot',\n",
       " 'charactor',\n",
       " u'charcat',\n",
       " 'charcter',\n",
       " u'charg',\n",
       " u'charit',\n",
       " u'chariti',\n",
       " u'charli',\n",
       " u'charm',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chatter',\n",
       " u'chatti',\n",
       " 'cheap',\n",
       " u'cheat',\n",
       " u'check',\n",
       " 'checklist',\n",
       " 'cheer',\n",
       " u'chew',\n",
       " 'chic',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'childrensteen',\n",
       " 'childrenyoung',\n",
       " 'chill',\n",
       " 'chimera',\n",
       " 'chip',\n",
       " 'chock',\n",
       " u'choic',\n",
       " u'choos',\n",
       " 'chop',\n",
       " u'choppi',\n",
       " 'choral',\n",
       " 'chore',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " u'christi',\n",
       " u'christma',\n",
       " u'chronicl',\n",
       " u'chuckl',\n",
       " 'churn',\n",
       " u'cinemat',\n",
       " u'circl',\n",
       " u'circumst',\n",
       " u'citi',\n",
       " u'citizen',\n",
       " 'civil',\n",
       " u'claim',\n",
       " 'clan',\n",
       " 'claptrap',\n",
       " u'clarenc',\n",
       " u'clariti',\n",
       " u'class',\n",
       " u'classconscieni',\n",
       " u'classi',\n",
       " 'classic',\n",
       " u'classifi',\n",
       " 'classism',\n",
       " 'classroom',\n",
       " u'claustrophob',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " u'clearli',\n",
       " 'clever',\n",
       " u'clich',\n",
       " 'click',\n",
       " 'cliff',\n",
       " u'cliffhang',\n",
       " u'climact',\n",
       " 'climax',\n",
       " 'climb',\n",
       " 'cling',\n",
       " u'clinic',\n",
       " u'clip',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " u'closur',\n",
       " 'cloud',\n",
       " u'cloudi',\n",
       " u'cloy',\n",
       " 'club',\n",
       " 'clubi',\n",
       " 'clue',\n",
       " u'clueless',\n",
       " u'clumsi',\n",
       " u'cluster',\n",
       " u'clutter',\n",
       " u'coars',\n",
       " 'coaster',\n",
       " u'cobbl',\n",
       " u'code',\n",
       " u'cohes',\n",
       " 'cold',\n",
       " u'collaps',\n",
       " u'colleagu',\n",
       " u'collect',\n",
       " u'colleg',\n",
       " u'collegeag',\n",
       " u'collis',\n",
       " u'collus',\n",
       " u'color',\n",
       " u'colorless',\n",
       " u'column',\n",
       " u'combat',\n",
       " u'combin',\n",
       " u'come',\n",
       " u'comedi',\n",
       " u'comeupp',\n",
       " u'comfort',\n",
       " u'comic',\n",
       " u'command',\n",
       " u'comment',\n",
       " u'commentari',\n",
       " u'commiser',\n",
       " u'commit',\n",
       " u'commodifi',\n",
       " 'common',\n",
       " u'commun',\n",
       " u'commut',\n",
       " u'compani',\n",
       " 'companion',\n",
       " u'compar',\n",
       " u'comparison',\n",
       " u'compass',\n",
       " u'compassion',\n",
       " u'compel',\n",
       " 'compendium',\n",
       " u'compens',\n",
       " u'compet',\n",
       " u'competit',\n",
       " u'compil',\n",
       " u'complac',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " u'complet',\n",
       " 'completeley',\n",
       " 'complex',\n",
       " u'complic',\n",
       " 'comprehend',\n",
       " u'compuls',\n",
       " u'comput',\n",
       " 'conceal',\n",
       " u'conceiv',\n",
       " u'concentr',\n",
       " 'concept',\n",
       " u'concern',\n",
       " u'concis',\n",
       " u'conclud',\n",
       " u'conclus',\n",
       " u'concret',\n",
       " 'condemn',\n",
       " u'condit',\n",
       " u'confederaci',\n",
       " u'confess',\n",
       " u'confid',\n",
       " u'confin',\n",
       " u'confirm',\n",
       " 'conflict',\n",
       " 'confront',\n",
       " u'confus',\n",
       " u'confusingli',\n",
       " 'confusiong',\n",
       " u'congratul',\n",
       " u'conjur',\n",
       " 'connect',\n",
       " u'conscienc',\n",
       " u'consciou',\n",
       " u'consensu',\n",
       " u'consequ',\n",
       " u'conserv',\n",
       " u'consid',\n",
       " u'consider',\n",
       " u'consist',\n",
       " u'consolid',\n",
       " 'constant',\n",
       " u'constantli',\n",
       " u'construct',\n",
       " u'consum',\n",
       " 'contain',\n",
       " u'contempl',\n",
       " u'contemporari',\n",
       " u'contemptu',\n",
       " 'content',\n",
       " 'context',\n",
       " u'contin',\n",
       " u'continu',\n",
       " u'contrari',\n",
       " 'contrast',\n",
       " u'contribut',\n",
       " u'contriv',\n",
       " 'control',\n",
       " u'controsept',\n",
       " u'convent',\n",
       " u'converg',\n",
       " u'convers',\n",
       " u'convey',\n",
       " u'convinc',\n",
       " u'convolut',\n",
       " 'cool',\n",
       " 'cope',\n",
       " u'copi',\n",
       " 'copperfield',\n",
       " 'core',\n",
       " 'cormoran',\n",
       " u'corneliu',\n",
       " u'coron',\n",
       " 'correct',\n",
       " u'correctli',\n",
       " u'corrupt',\n",
       " 'cost',\n",
       " 'costco',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'council',\n",
       " 'councillor',\n",
       " 'councilman',\n",
       " u'counsellor',\n",
       " 'count',\n",
       " u'counter',\n",
       " u'counterbalanc',\n",
       " u'counterpart',\n",
       " u'counterpoint',\n",
       " u'countless',\n",
       " u'countri',\n",
       " u'countrysid',\n",
       " u'coupl',\n",
       " u'courag',\n",
       " u'cours',\n",
       " u'cover',\n",
       " u'cowardic',\n",
       " u'cozi',\n",
       " 'craft',\n",
       " u'cram',\n",
       " 'crap',\n",
       " u'crappi',\n",
       " 'crappola',\n",
       " u'crash',\n",
       " u'crass',\n",
       " u'crave',\n",
       " u'crazi',\n",
       " u'creat',\n",
       " 'creation',\n",
       " u'creativ',\n",
       " u'creatur',\n",
       " u'credibl',\n",
       " u'creep',\n",
       " u'creepi',\n",
       " 'crescendo',\n",
       " u'cri',\n",
       " 'crime',\n",
       " u'crimin',\n",
       " u'cring',\n",
       " u'crippl',\n",
       " 'criteria',\n",
       " u'critic',\n",
       " u'cross',\n",
       " 'crowd',\n",
       " 'crude',\n",
       " 'cruel',\n",
       " 'cruelest',\n",
       " u'cruelti',\n",
       " u'cruis',\n",
       " u'crumbl',\n",
       " u'crummi',\n",
       " 'cs',\n",
       " u'cubbi',\n",
       " 'cuckoo',\n",
       " u'culmin',\n",
       " u'cultur',\n",
       " u'cumbersom',\n",
       " 'cup',\n",
       " u'cure',\n",
       " u'curios',\n",
       " u'curiou',\n",
       " 'current',\n",
       " u'curs',\n",
       " 'curt',\n",
       " u'curtail',\n",
       " 'curtain',\n",
       " u'cuss',\n",
       " u'cussi',\n",
       " 'cut',\n",
       " u'cutout',\n",
       " 'cword',\n",
       " u'cycl',\n",
       " u'cynic',\n",
       " 'dahl',\n",
       " u'daili',\n",
       " u'dalla',\n",
       " u'damag',\n",
       " 'dan',\n",
       " u'dandi',\n",
       " 'danger',\n",
       " u'dangl',\n",
       " u'daniel',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'darker',\n",
       " 'darkest',\n",
       " u'darkli',\n",
       " u'darn',\n",
       " 'dash',\n",
       " u'dataentri',\n",
       " ...]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Transformed feature matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50171821305841924"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 6, weights = 'uniform').fit(train_X, train_c)\n",
    "accuracy = model.score(test_X, test_c)\n",
    "misclassification_error = 1 - accuracy\n",
    "\n",
    "misclassification_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-f06c427db5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/metrics/scorer.pyc\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_cv = 10 # 10-fold CV\n",
    "k_nn = range(1, df.shape[0] * (k_cv - 1) / k_cv) # k-NN\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': k_nn},\n",
    "    cv = model_selection.KFold(n_splits = k_cv, shuffle = True, random_state = 0)\n",
    ")\n",
    "\n",
    "gs.fit(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-179e7fb439ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mbest_score_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbest_score_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cv_results_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# FIXME NotFittedError_ --> NotFittedError in 0.19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_NotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> # TODO..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
